{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "7CTPKhG7-B0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install sox\n",
        "!pip install ffmpeg"
      ],
      "metadata": {
        "id": "xIbXVEEGWJ87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2436ce0c-08b7-4be0-8385-b2ea56f6673d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3\n",
            "Suggested packages:\n",
            "  file libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3 sox\n",
            "0 upgraded, 8 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 760 kB of archives.\n",
            "After this operation, 6,717 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrnb0 amd64 0.1.3-2.1 [92.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrwb0 amd64 0.1.3-2.1 [45.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox3 amd64 14.4.2-3ubuntu0.18.04.1 [226 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2-3ubuntu0.18.04.1 [10.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-base amd64 14.4.2-3ubuntu0.18.04.1 [32.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 sox amd64 14.4.2-3ubuntu0.18.04.1 [101 kB]\n",
            "Fetched 760 kB in 2s (456 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 8.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 123934 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../2-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../3-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../4-libsox3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../5-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../6-libsox-fmt-base_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../7-sox_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6084 sha256=bd2a70e8dd780d5f6e1f7cfa0857cac721f3a57695a2f7bb431cb8d9b6b844d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z9YtcdHOXfMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/HTS-Audio-Transformer/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ2obkgtWsDo",
        "outputId": "2e2fe3df-38a7-4d59-874e-8323e4b642fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/HTS-Audio-Transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "UNPHx554XgFh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9793410f-0c42-4760-98a2-fa14ed69130c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h5py==3.6.0\n",
            "  Downloading h5py-3.6.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 29.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.8.1)\n",
            "Collecting matplotlib==3.5.1\n",
            "  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting museval==0.4.0\n",
            "  Downloading museval-0.4.0-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy<=1.22.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: pandas<=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.3.5)\n",
            "Collecting pytorch_lightning==1.5.9\n",
            "  Downloading pytorch_lightning-1.5.9-py3-none-any.whl (527 kB)\n",
            "\u001b[K     |████████████████████████████████| 527 kB 72.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit_learn==1.0.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.0.2)\n",
            "Requirement already satisfied: scipy==1.7.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.7.3)\n",
            "Collecting soundfile==0.10.3.post1\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: tensorboard==2.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (2.8.0)\n",
            "Collecting torchcontrib==0.0.2\n",
            "  Downloading torchcontrib-0.0.2.tar.gz (11 kB)\n",
            "Collecting torchlibrosa==0.0.9\n",
            "  Downloading torchlibrosa-0.0.9-py3-none-any.whl (11 kB)\n",
            "Collecting tqdm==4.62.3\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (7.7.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (4.4.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py==3.6.0->-r requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->-r requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->-r requirements.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->-r requirements.txt (line 2)) (0.56.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->-r requirements.txt (line 2)) (0.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->-r requirements.txt (line 2)) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->-r requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->-r requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->-r requirements.txt (line 3)) (3.0.9)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.37.4-py3-none-any.whl (960 kB)\n",
            "\u001b[K     |████████████████████████████████| 960 kB 64.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from museval==0.4.0->-r requirements.txt (line 4)) (4.3.3)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 67.8 MB/s \n",
            "\u001b[?25hCollecting musdb>=0.4.0\n",
            "  Downloading musdb-0.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.10.0-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 76.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (4.1.1)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 72.0 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (6.0)\n",
            "Collecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 30.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (1.12.1+cu113)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (2022.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.2->-r requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile==0.10.3.post1->-r requirements.txt (line 10)) (1.15.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (1.49.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0->-r requirements.txt (line 11)) (1.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.4.0->-r requirements.txt (line 6)) (2022.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile==0.10.3.post1->-r requirements.txt (line 10)) (2.21)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (3.8.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (1.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.9->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0->-r requirements.txt (line 11)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0->-r requirements.txt (line 11)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0->-r requirements.txt (line 11)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0->-r requirements.txt (line 11)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8.0->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==2.8.0->-r requirements.txt (line 11)) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.8.0->-r requirements.txt (line 11)) (3.8.1)\n",
            "Collecting pyaml\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting stempeg>=0.2.3\n",
            "  Downloading stempeg-0.2.3-py3-none-any.whl (963 kB)\n",
            "\u001b[K     |████████████████████████████████| 963 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.1->-r requirements.txt (line 2)) (0.39.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.1->-r requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.8.0->-r requirements.txt (line 11)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0->-r requirements.txt (line 11)) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8.0->-r requirements.txt (line 11)) (3.2.1)\n",
            "Collecting ffmpeg-python>=0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (5.1.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (5.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (0.13.3)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (5.1.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (4.11.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (6.1.12)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (5.3.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->-r requirements.txt (line 16)) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook->-r requirements.txt (line 16)) (23.2.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->-r requirements.txt (line 16)) (0.7.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->-r requirements.txt (line 17)) (3.0.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->-r requirements.txt (line 17)) (7.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->-r requirements.txt (line 17)) (3.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 17)) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 17)) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 17)) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 17)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 17)) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 58.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 17)) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 17)) (0.2.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown->-r requirements.txt (line 18)) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown->-r requirements.txt (line 18)) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->-r requirements.txt (line 16)) (2.0.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->museval==0.4.0->-r requirements.txt (line 4)) (5.9.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->museval==0.4.0->-r requirements.txt (line 4)) (0.18.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->-r requirements.txt (line 16)) (0.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->-r requirements.txt (line 16)) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->-r requirements.txt (line 16)) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->-r requirements.txt (line 16)) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->-r requirements.txt (line 16)) (5.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->-r requirements.txt (line 16)) (0.8.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->-r requirements.txt (line 16)) (2.16.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->-r requirements.txt (line 16)) (0.5.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0->-r requirements.txt (line 11)) (1.7.1)\n",
            "Building wheels for collected packages: torchcontrib, future, wget\n",
            "  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-py3-none-any.whl size=7533 sha256=0692802b32517f0d973a221b45aa79d4a658fccf1c9a0c92059847cabdd3f07c\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/58/d0/f03811c3e34e1f14031294b5f30d8693689972af874d1225b8\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=9ed209c2777ec9d715609d98e6a3f82805e383a8eb3f3e4b64060a4dd60b9c3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=bad3d5d1daea3db80dede08a87fb2f2e32562b9637a505f5a0c8280c99bf8921\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built torchcontrib future wget\n",
            "Installing collected packages: setuptools, jedi, future, ffmpeg-python, tqdm, stempeg, soundfile, pyaml, torchmetrics, simplejson, pyDeprecate, musdb, fonttools, wget, torchlibrosa, torchcontrib, pytorch-lightning, museval, matplotlib, h5py\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: soundfile\n",
            "    Found existing installation: soundfile 0.11.0\n",
            "    Uninstalling soundfile-0.11.0:\n",
            "      Successfully uninstalled soundfile-0.11.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed ffmpeg-python-0.2.0 fonttools-4.37.4 future-0.18.2 h5py-3.6.0 jedi-0.18.1 matplotlib-3.5.1 musdb-0.4.0 museval-0.4.0 pyDeprecate-0.3.1 pyaml-21.10.1 pytorch-lightning-1.5.9 setuptools-59.5.0 simplejson-3.17.6 soundfile-0.10.3.post1 stempeg-0.2.3 torchcontrib-0.0.2 torchlibrosa-0.0.9 torchmetrics-0.10.0 tqdm-4.62.3 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xAdcBt93p-"
      },
      "source": [
        "## Tutorial on training a HTS-AT model for audio classification on the ESC-50 Dataset\n",
        "\n",
        "Referece: \n",
        "\n",
        "[HTS-AT: A Hierarchical Token-Semantic Audio Transformer for Sound Classification and Detection, ICASSP 2022](https://arxiv.org/abs/2202.00874)\n",
        "\n",
        "Following the HTS-AT's paper, in this tutorial, we would show how to use the HST-AT in the training of the ESC-50 Dataset.\n",
        "\n",
        "The [ESC-50 dataset](https://github.com/karolpiczak/ESC-50) is a labeled collection of 2000 environmental audio recordings suitable for benchmarking methods of environmental sound classification. The dataset consists of 5-second-long recordings organized into 50 semantical classes (with 40 examples per class) loosely arranged into 5 major categories\n",
        "\n",
        "Before running this tutorial, please make sure that you install the below packages by following steps:\n",
        "\n",
        "1. download [the codebase](https://github.com/RetroCirce/HTS-Audio-Transformer), and put this tutorial notebook inside the codebase folder.\n",
        "\n",
        "2. In the github code folder:\n",
        "\n",
        "    > pip install -r requirements.txt\n",
        "\n",
        "3. We do not include the installation of PyTorch in the requirment, since different machines require different vereions of CUDA and Toolkits. So make sure you install the PyTorch from [the official guidance](https://pytorch.org/).\n",
        "\n",
        "4. Install the 'SOX' and the 'ffmpeg', we recommend that you run this code in Linux inside the Conda environment. In that, you can install them by:\n",
        "\n",
        "    > sudo apt install sox\n",
        "    \n",
        "    > conda install -c conda-forge ffmpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dqp-GUAH-ENE",
        "outputId": "c44e7845-41a6-412a-8cca-2c31d6be5d15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQKzPoYu93qF"
      },
      "outputs": [],
      "source": [
        "# import basic packages\n",
        "import os\n",
        "import numpy as np\n",
        "import wget\n",
        "import sys\n",
        "import gdown\n",
        "import zipfile\n",
        "import librosa\n",
        "# in the notebook, we only can use one GPU\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process ESC-50 Dataset\n",
        "\n",
        "workspace = \"/content/drive/MyDrive/HTS-Audio-Transformer\"\n",
        "dataset_path = os.path.join(workspace, \"esc-50\")\n",
        "checkpoint_path = os.path.join(workspace, \"ckpt\")\n",
        "esc_raw_path = os.path.join(dataset_path, 'raw')\n",
        "\n",
        "meta_path = os.path.join(esc_raw_path, 'ESC-50-master', 'meta', 'esc50.csv')\n",
        "audio_path = os.path.join(esc_raw_path, 'ESC-50-master', 'audio')\n",
        "resample_path = os.path.join(dataset_path, 'resample')\n",
        "savedata_path = os.path.join(dataset_path, 'esc-50-data.npy')"
      ],
      "metadata": {
        "id": "knFU_-o6eQOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5_uv7MH93qH"
      },
      "outputs": [],
      "source": [
        "# Build the workspace and download the needed files\n",
        "\n",
        "def create_path(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)\n",
        "\n",
        "\n",
        "create_path(workspace)\n",
        "create_path(dataset_path)\n",
        "create_path(checkpoint_path)\n",
        "create_path(esc_raw_path)\n",
        "\n",
        "\n",
        "# download the esc-50 dataset\n",
        "\n",
        "if not os.path.exists(os.path.join(dataset_path, 'ESC-50-master.zip')):\n",
        "    print(\"-------------Downloading ESC-50 Dataset-------------\")\n",
        "    wget.download('https://github.com/karoldvl/ESC-50/archive/master.zip', out=dataset_path)\n",
        "    with zipfile.ZipFile(os.path.join(dataset_path, 'ESC-50-master.zip'), 'r') as zip_ref:\n",
        "        zip_ref.extractall(esc_raw_path)\n",
        "    print(\"-------------Success-------------\")\n",
        "\n",
        "if not os.path.exists(os.path.join(checkpoint_path,'htsat_audioset_pretrain.ckpt')):\n",
        "    gdown.download(id='1OK8a5XuMVLyeVKF117L8pfxeZYdfSDZv', output=os.path.join(checkpoint_path,'htsat_audioset_pretrain.ckpt'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "615CMyNLeLPY",
        "outputId": "cf02ebca-c24b-44f2-ae8d-2a02c212f4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-35b4eb7557f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Process ESC-50 Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmeta_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesc_raw_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ESC-50-master'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'esc50.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maudio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesc_raw_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ESC-50-master'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'audio'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresample_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resample'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msavedata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'esc-50-data.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'esc_raw_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FLKbDrC93qI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ab5cb3-d499-4490-860a-70d65edf22a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------Resample ESC-50-------------\n",
            "-------------Success-------------\n",
            "-------------Build Dataset-------------\n",
            "-------------Success-------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "create_path(resample_path)\n",
        "\n",
        "meta = np.loadtxt(meta_path , delimiter=',', dtype='str', skiprows=1)\n",
        "audio_list = os.listdir(audio_path)\n",
        "\n",
        "# resample\n",
        "print(\"-------------Resample ESC-50-------------\")\n",
        "for f in audio_list:\n",
        "    full_f = os.path.join(audio_path, f)\n",
        "    resample_f = os.path.join(resample_path, f)\n",
        "    if not os.path.exists(resample_f):\n",
        "        os.system('sox -V1 ' + full_f + ' -r 32000 ' + resample_f)\n",
        "print(\"-------------Success-------------\")\n",
        "\n",
        "print(\"-------------Build Dataset-------------\")\n",
        "output_dict = [[] for _ in range(5)]\n",
        "for label in meta:\n",
        "    name = label[0]\n",
        "    fold = label[1]\n",
        "    target = label[2]\n",
        "    y, sr = librosa.load(os.path.join(resample_path, name), sr = None)\n",
        "    output_dict[int(fold) - 1].append(\n",
        "        {\n",
        "            \"name\": name,\n",
        "            \"target\": int(target),\n",
        "            \"waveform\": y\n",
        "        }\n",
        "    )\n",
        "np.save(savedata_path, output_dict)\n",
        "print(\"-------------Success-------------\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download(id='1YRkS-09DUR1zVb9-GorjscjcIJq_pa2H', output=os.path.join(checkpoint_path,'htsat_esc-50_pretrain.ckpt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "K4dGCHkAcimb",
        "outputId": "5ab2dc3c-8e71-45c9-948f-842f67c4df52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YRkS-09DUR1zVb9-GorjscjcIJq_pa2H\n",
            "To: /content/drive/MyDrive/HTS-Audio-Transformer/ckpt/htsat_esc-50_pretrain.ckpt\n",
            "100%|██████████| 340M/340M [00:08<00:00, 40.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/HTS-Audio-Transformer/ckpt/htsat_esc-50_pretrain.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision torchtext==0.8.1 torchaudio"
      ],
      "metadata": {
        "id": "AC7SwYzWZtgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3SqVYdp93qJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c246bf8f-288c-4a66-9301-3b5505f9fae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n"
          ]
        }
      ],
      "source": [
        "# Load the model package\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import warnings\n",
        "\n",
        "from utils import create_folder, dump_config, process_idc\n",
        "import esc_config as config\n",
        "from sed_model import SEDWrapper, Ensemble_SEDWrapper\n",
        "from data_generator import ESC_Dataset\n",
        "from model.htsat import HTSAT_Swin_Transformer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tQ4wYMq93qK"
      },
      "outputs": [],
      "source": [
        "# Data Preparation\n",
        "class data_prep(pl.LightningDataModule):\n",
        "    def __init__(self, train_dataset, eval_dataset, device_num):\n",
        "        super().__init__()\n",
        "        self.train_dataset = train_dataset\n",
        "        self.eval_dataset = eval_dataset\n",
        "        self.device_num = device_num\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_sampler = DistributedSampler(self.train_dataset, shuffle = False) if self.device_num > 1 else None\n",
        "        train_loader = DataLoader(\n",
        "            dataset = self.train_dataset,\n",
        "            num_workers = config.num_workers,\n",
        "            batch_size = config.batch_size // self.device_num,\n",
        "            shuffle = False,\n",
        "            sampler = train_sampler\n",
        "        )\n",
        "        return train_loader\n",
        "    def val_dataloader(self):\n",
        "        eval_sampler = DistributedSampler(self.eval_dataset, shuffle = False) if self.device_num > 1 else None\n",
        "        eval_loader = DataLoader(\n",
        "            dataset = self.eval_dataset,\n",
        "            num_workers = config.num_workers,\n",
        "            batch_size = config.batch_size // self.device_num,\n",
        "            shuffle = False,\n",
        "            sampler = eval_sampler\n",
        "        )\n",
        "        return eval_loader\n",
        "    def test_dataloader(self):\n",
        "        test_sampler = DistributedSampler(self.eval_dataset, shuffle = False) if self.device_num > 1 else None\n",
        "        test_loader = DataLoader(\n",
        "            dataset = self.eval_dataset,\n",
        "            num_workers = config.num_workers,\n",
        "            batch_size = config.batch_size // self.device_num,\n",
        "            shuffle = False,\n",
        "            sampler = test_sampler\n",
        "        )\n",
        "        return test_loader\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ-pcbrG93qL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f1ed8c-43a3-4767-e398-2056f235ba1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "each batch size: 64\n",
            "Using ESC\n"
          ]
        }
      ],
      "source": [
        "# Set the workspace\n",
        "device_num = torch.cuda.device_count()\n",
        "print(\"each batch size:\", config.batch_size // device_num)\n",
        "\n",
        "full_dataset = np.load(os.path.join(config.dataset_path, \"esc-50-data.npy\"), allow_pickle = True)\n",
        "\n",
        "# set exp folder\n",
        "exp_dir = os.path.join(config.workspace, \"results\", config.exp_name)\n",
        "checkpoint_dir = os.path.join(config.workspace, \"results\", config.exp_name, \"checkpoint\")\n",
        "if not config.debug:\n",
        "    create_folder(os.path.join(config.workspace, \"results\"))\n",
        "    create_folder(exp_dir)\n",
        "    create_folder(checkpoint_dir)\n",
        "    dump_config(config, os.path.join(exp_dir, config.exp_name), False)\n",
        "\n",
        "print(\"Using ESC\")\n",
        "dataset = ESC_Dataset(\n",
        "    dataset = full_dataset,\n",
        "    config = config,\n",
        "    eval_mode = False\n",
        ")\n",
        "eval_dataset = ESC_Dataset(\n",
        "    dataset = full_dataset,\n",
        "    config = config,\n",
        "    eval_mode = True\n",
        ")\n",
        "\n",
        "audioset_data = data_prep(dataset, eval_dataset, device_num)\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor = \"acc\",\n",
        "    filename='l-{epoch:d}-{acc:.3f}',\n",
        "    save_top_k = 20,\n",
        "    mode = \"max\"\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuB0HW9V93qM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a15ba5-3e78-4736-9d8a-d5446526f3dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.distributed:GPU available: True, used: True\n",
            "INFO:pytorch_lightning.utilities.distributed:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.distributed:IPU available: False, using: 0 IPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load Checkpoint from  /content/drive/MyDrive/HTS-Audio-Transformer/ckpt/htsat_esc-50_pretrain.ckpt\n"
          ]
        }
      ],
      "source": [
        "# Set the Trainer\n",
        "trainer = pl.Trainer(\n",
        "    deterministic=False,\n",
        "    default_root_dir = checkpoint_dir,\n",
        "    gpus = device_num, \n",
        "    val_check_interval = 1.0,\n",
        "    max_epochs = config.max_epoch,\n",
        "    auto_lr_find = True,    \n",
        "    sync_batchnorm = True,\n",
        "    callbacks = [checkpoint_callback],\n",
        "    accelerator = \"ddp\" if device_num > 1 else None,\n",
        "    num_sanity_val_steps = 0,\n",
        "    resume_from_checkpoint = None, \n",
        "    replace_sampler_ddp = False,\n",
        "    gradient_clip_val=1.0\n",
        ")\n",
        "\n",
        "sed_model = HTSAT_Swin_Transformer(\n",
        "    spec_size=config.htsat_spec_size,\n",
        "    patch_size=config.htsat_patch_size,\n",
        "    in_chans=1,\n",
        "    num_classes=config.classes_num,\n",
        "    window_size=config.htsat_window_size,\n",
        "    config = config,\n",
        "    depths = config.htsat_depth,\n",
        "    embed_dim = config.htsat_dim,\n",
        "    patch_stride=config.htsat_stride,\n",
        "    num_heads=config.htsat_num_head\n",
        ")\n",
        "\n",
        "model = SEDWrapper(\n",
        "    sed_model = sed_model, \n",
        "    config = config,\n",
        "    dataset = dataset\n",
        ")\n",
        "\n",
        "if config.resume_checkpoint is not None:\n",
        "    print(\"Load Checkpoint from \", config.resume_checkpoint)\n",
        "    ckpt = torch.load(config.resume_checkpoint, map_location=\"cpu\")\n",
        "    ckpt[\"state_dict\"].pop(\"sed_model.head.weight\")\n",
        "    ckpt[\"state_dict\"].pop(\"sed_model.head.bias\")\n",
        "    # finetune on the esc and spv2 dataset\n",
        "    ckpt[\"state_dict\"].pop(\"sed_model.tscam_conv.weight\")\n",
        "    ckpt[\"state_dict\"].pop(\"sed_model.tscam_conv.bias\")\n",
        "    model.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiFKjLm_93qN"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "# You can set different fold index by setting 'esc_fold' to any number from 0-4 in esc_config.py\n",
        "trainer.fit(model, audioset_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd6OJNbS93qN"
      },
      "source": [
        "## Now Let us Check the Result\n",
        "\n",
        "Find the path of your saved checkpoint and paste it in the below variable.\n",
        "Then you are able to follow the below code for checking the prediction result of any sample you like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cn4Fonf93qO"
      },
      "outputs": [],
      "source": [
        "# infer the single data to check the result\n",
        "# get a model you saved\n",
        "model_path = '/content/drive/MyDrive/HTS-Audio-Transformer/ckpt/htsat_esc-50_pretrain.ckpt'\n",
        "\n",
        "# get the groundtruth\n",
        "meta = np.loadtxt(meta_path , delimiter=',', dtype='str', skiprows=1)\n",
        "gd = {}\n",
        "for label in meta:\n",
        "    name = label[0]\n",
        "    target = label[2]\n",
        "    gd[target] = label[3]\n",
        "# for label in meta:\n",
        "#     name = label[0]\n",
        "#     target = label[2]\n",
        "#     gd[name] = target\n",
        "\n",
        "class Audio_Classification:\n",
        "    def __init__(self, model_path, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = torch.device('cuda')\n",
        "        self.sed_model = HTSAT_Swin_Transformer(\n",
        "            spec_size=config.htsat_spec_size,\n",
        "            patch_size=config.htsat_patch_size,\n",
        "            in_chans=1,\n",
        "            num_classes=config.classes_num,\n",
        "            window_size=config.htsat_window_size,\n",
        "            config = config,\n",
        "            depths = config.htsat_depth,\n",
        "            embed_dim = config.htsat_dim,\n",
        "            patch_stride=config.htsat_stride,\n",
        "            num_heads=config.htsat_num_head\n",
        "        )\n",
        "        ckpt = torch.load(model_path, map_location=\"cpu\")\n",
        "        temp_ckpt = {}\n",
        "        for key in ckpt[\"state_dict\"]:\n",
        "            temp_ckpt[key[10:]] = ckpt['state_dict'][key]\n",
        "        self.sed_model.load_state_dict(temp_ckpt)\n",
        "        self.sed_model.to(self.device)\n",
        "        self.sed_model.eval()\n",
        "\n",
        "\n",
        "    def predict(self, audiofile):\n",
        "\n",
        "        if audiofile:\n",
        "            waveform, sr = librosa.load(audiofile, sr=32000)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                x = torch.from_numpy(waveform).float().to(self.device)\n",
        "                output_dict = self.sed_model(x[None, :], None, True)\n",
        "                pred = output_dict['clipwise_output']\n",
        "                pred_post = pred[0].detach().cpu().numpy()\n",
        "                pred_label = np.argmax(pred_post)\n",
        "                pred_prob = np.max(pred_post)\n",
        "            return pred_label, pred_prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xboq2aaB93qP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94691fb2-27fb-420d-83de-3a5904b9e666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audiocls predict output:  9 4.544963 crow\n"
          ]
        }
      ],
      "source": [
        "# Inference\n",
        "Audiocls = Audio_Classification(model_path, config)\n",
        "\n",
        "# pick any audio you like in the ESC-50 testing set (cross-validation)\n",
        "pred_label, pred_prob = Audiocls.predict(\"/content/Recording (2).m4a\")\n",
        "\n",
        "print('Audiocls predict output: ', pred_label, pred_prob, gd[f\"{pred_label}\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e_0tdYUsi24B"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 ('kechen_py38')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "cb1a0df39641c41734bdd2d42699ec57167c4cf18fd061cdef52c16cce6262af"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}