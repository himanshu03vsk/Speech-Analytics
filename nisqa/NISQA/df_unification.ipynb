{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nisqa = pd.read_csv(\"results/NISQA_results.csv\")\n",
    "df_nisqa.reset_index()\n",
    "df_nisqa.index = range(df_nisqa.shape[0])\n",
    "df_splitter = pd.read_csv(\"df.csv\")\n",
    "df_splitter = df_splitter.astype({'filename': 'string','transcript':'string', 'accent':'string' })\n",
    "df_nisqa[\"filename\"] = df_nisqa[\"deg\"]\n",
    "df_nisqa = df_nisqa.drop([\"deg\"],axis=1)\n",
    "\n",
    "split_params = ['duration','transcript','confidence','age','gender','accent']\n",
    "# csv_nisqa_params = ['mos_pred', 'nos_pred', 'dis_pred', 'col_pred','loud_pred', 'model']\n",
    "for fields in split_params:\n",
    "    df_nisqa[fields] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in df_nisqa.index:\n",
    "    from math import ceil\n",
    "    parent_audio_part = df_nisqa.loc[i, \"filename\"].split(\"_\")[0:2] #using this because chunks are seperated by _\n",
    "    # parent_audio_part[1] = parent_audio_part[1][:-4] #this cuts off the .wav file extension This will be commented in final code as last part will contain extension and we dont need it call_0 -> needed \"_1.wav\" -> discard\n",
    "    parent_audio = \"_\".join(parent_audio_part)\n",
    "    original_params = df_splitter.loc[df_splitter[\"filename\"] == parent_audio]\n",
    "    transcript = original_params.loc[:, \"transcript\"].split()\n",
    "    original_params = df_splitter.loc[df_splitter[\"filename\"] == parent_audio]\n",
    "    duration = original_params[\"duration\"]\n",
    "    no_of_subaudios = ceil(duration/5)\n",
    "    chunk_size = ceil(len(transcript)/no_of_subaudios)\n",
    "    list_chunked = [transcript[j:j + chunk_size] for j in range(0, len(transcript), chunk_size)]\n",
    "    sentence = []\n",
    "    for word in list_chunked:\n",
    "        sentence.append(\" \".join(word))\n",
    "    \n",
    "    if parent_audio in df_nisqa.loc[i,\"filename\"]:\n",
    "        same_flag = True\n",
    "        # insert transcript here \n",
    "        # i can use try except block here for handling list index out of range\n",
    "        try:\n",
    "            df_nisqa.loc[i,\"transcript\"] = sentence[counter]\n",
    "        except IndexError:\n",
    "            df_nisqa.loc[i,\"transcript\"] = \"\"\n",
    "        same_flag = False\n",
    "        counter+=1\n",
    "        # except NameError:\n",
    "        #     counter = 0\n",
    "    else:\n",
    "        same_flag = False\n",
    "        counter = 0\n",
    "    # break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nisqa = pd.read_csv(\"results/NISQA_results.csv\")\n",
    "df_nisqa.reset_index()\n",
    "df_nisqa.index = range(df_nisqa.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nisqa.loc[1, \"transcript\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "df_nisqa = pd.read_csv(\"results/NISQA_results.csv\")\n",
    "df_nisqa.reset_index(inplace=True)\n",
    "df_nisqa.index = range(df_nisqa.shape[0])\n",
    "df_splitter = pd.read_csv(\"df.csv\")\n",
    "df_splitter = df_splitter.astype({'filename': 'string','transcript':'string', 'accent':'string' })\n",
    "df_nisqa[\"filename\"] = df_nisqa[\"deg\"]\n",
    "df_nisqa = df_nisqa.drop([\"deg\"],axis=1)\n",
    "df_new = pd.DataFrame()\n",
    "\n",
    "# split_params = ['duration','transcript','confidence','age','gender','accent']\n",
    "csv_nisqa_params = ['filename', 'duration', 'transcript', 'confidence', 'age', 'gender','accent' ,'mos_pred', 'noi_pred', 'dis_pred', 'col_pred','loud_pred', 'model']\n",
    "for fields in csv_nisqa_params:\n",
    "    df_new[fields] = ''\n",
    "extra_nisqa_params = ['filename', 'duration', 'transcript', 'confidence', 'age', 'gender','accent']\n",
    "\n",
    "def make_chunks(transcript: str, chunk_length: int, number_of_chunks: int):\n",
    "    return [transcript[i * chunk_length:(i + 1) * chunk_length]\n",
    "            for i in range(int(number_of_chunks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Himanshu\\AppData\\Local\\Temp\\ipykernel_8640\\1066049726.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunks[fields] = ''\n",
      "c:\\Users\\Himanshu\\anaconda3\\envs\\nisqa\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "for i in df_splitter.index:\n",
    "    # print(\"iteration \", i)\n",
    "    parent_params = df_splitter.loc[i]\n",
    "    filename = parent_params.loc[\"filename\"]\n",
    "    concerned_params = df_splitter.loc[i, [\"filename\", \"duration\",\"confidence\", \"age\", \"gender\", \"accent\"]]\n",
    "    transcript = df_splitter.loc[i, \"transcript\"]\n",
    "    chunks = df_nisqa[df_nisqa[\"filename\"].str.contains(filename)]\n",
    "    chunks.reset_index(inplace=True)\n",
    "    for fields in extra_nisqa_params:\n",
    "        chunks[fields] = ''\n",
    "    no_of_sub_calls = chunks.shape[0]\n",
    "    chunk_length = ceil(len(transcript)/no_of_sub_calls)\n",
    "    # print(no_of_sub_calls)\n",
    "    sub_transcripts = make_chunks(transcript, chunk_length, no_of_sub_calls)\n",
    "    # print(sub_transcripts)\n",
    "    # print(len(chunks.index), \"\\n\",len(sub_transcripts))\n",
    "    # break\n",
    "    # print(i)\n",
    "    for sub_chunks in chunks.index:\n",
    "        # print(\"Sub_ ITERATION \", sub_chunks)\n",
    "        # print(sub_chunks)\n",
    "        # print(chunks.loc[sub_chunks, \"transcript\"])\n",
    "        chunks.loc[sub_chunks, \"transcript\"] = sub_transcripts[sub_chunks]\n",
    "        # final_parameters = pd.concat([concerned_params, chunks.loc[sub_chunks]], axis=1, ignore_index=True)\n",
    "        # print({'filename': df_nisqa.loc[sub_chunks, \"filename\"], 'duration': df_splitter.loc[i, \"duration\"], 'confidence':concerned_params.loc[\"confidence\"],'age':concerned_params.loc[\"age\"],'gender': concerned_params.loc[\"gender\"], 'accent': concerned_params.loc[\"accent\"],'mos_pred': chunks.loc[sub_chunks, \"mos_pred\"], 'noi_pred':chunks.loc[sub_chunks, \"noi_pred\"], 'dis_pred': chunks.loc[sub_chunks, \"dis_pred\"], 'col_pred':chunks.loc[sub_chunks, \"col_pred\"], 'loud_pred':chunks.loc[sub_chunks, \"loud_pred\"], 'model':chunks.loc[sub_chunks, \"model\"], 'transcript':chunks.loc[sub_chunks, \"transcript\"]})\n",
    "        df_new = df_new.append({'filename': df_nisqa.loc[sub_chunks, \"filename\"], 'duration': df_splitter.loc[i, \"duration\"], 'confidence':concerned_params.loc[\"confidence\"],'age':concerned_params.loc[\"age\"],'gender': concerned_params.loc[\"gender\"], 'accent': concerned_params.loc[\"accent\"],'mos_pred': chunks.loc[sub_chunks, \"mos_pred\"], 'noi_pred':chunks.loc[sub_chunks, \"noi_pred\"], 'dis_pred': chunks.loc[sub_chunks, \"dis_pred\"], 'col_pred':chunks.loc[sub_chunks, \"col_pred\"], 'loud_pred':chunks.loc[sub_chunks, \"loud_pred\"], 'model':chunks.loc[sub_chunks, \"model\"], 'transcript':chunks.loc[sub_chunks, \"transcript\"]}, ignore_index=True)\n",
    "\n",
    "    # break\n",
    "        # print(final_parameters)\n",
    "        # df_new = df_new.append(final_parameters, ignore_index=True)\n",
    "    \n",
    "df_new = df_new.sort_values('noi_pred')\n",
    "df_new.reset_index(inplace=True)\n",
    "df_new.drop([\"index\"], axis=1, inplace=True)\n",
    "df_new.to_csv('final_data.csv')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>duration</th>\n",
       "      <th>transcript</th>\n",
       "      <th>confidence</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>mos_pred</th>\n",
       "      <th>noi_pred</th>\n",
       "      <th>dis_pred</th>\n",
       "      <th>col_pred</th>\n",
       "      <th>loud_pred</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OutboundSampleRecording_0_2</td>\n",
       "      <td>22</td>\n",
       "      <td>I am her  to make yo</td>\n",
       "      <td>-3.789234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581293</td>\n",
       "      <td>1.521738</td>\n",
       "      <td>4.343019</td>\n",
       "      <td>3.584870</td>\n",
       "      <td>3.764795</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OutboundSampleRecording_0_1</td>\n",
       "      <td>6</td>\n",
       "      <td>Hello tre</td>\n",
       "      <td>-3.312910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.809590</td>\n",
       "      <td>1.875911</td>\n",
       "      <td>3.833058</td>\n",
       "      <td>3.287724</td>\n",
       "      <td>2.815992</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OutboundSampleRecording_0_2</td>\n",
       "      <td>6</td>\n",
       "      <td>my love</td>\n",
       "      <td>-3.312910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.742911</td>\n",
       "      <td>1.892213</td>\n",
       "      <td>3.259427</td>\n",
       "      <td>2.251022</td>\n",
       "      <td>2.962693</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OutboundSampleRecording_0_4</td>\n",
       "      <td>22</td>\n",
       "      <td>then I qwill carry ea</td>\n",
       "      <td>-3.789234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.635692</td>\n",
       "      <td>1.920747</td>\n",
       "      <td>3.986793</td>\n",
       "      <td>3.092535</td>\n",
       "      <td>3.441731</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OutboundSampleRecording_0_1</td>\n",
       "      <td>5</td>\n",
       "      <td>see the ocean ovwer there</td>\n",
       "      <td>-15.193325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.008507</td>\n",
       "      <td>1.956141</td>\n",
       "      <td>3.775151</td>\n",
       "      <td>3.138167</td>\n",
       "      <td>2.895992</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OutboundSampleRecording_0_5</td>\n",
       "      <td>22</td>\n",
       "      <td>ch of you to the back</td>\n",
       "      <td>-3.789234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.189593</td>\n",
       "      <td>2.064310</td>\n",
       "      <td>3.807749</td>\n",
       "      <td>3.011560</td>\n",
       "      <td>3.009693</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OutboundSampleRecording_0_1</td>\n",
       "      <td>4</td>\n",
       "      <td>I am going to the movies do you want to go</td>\n",
       "      <td>-6.178956</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.058475</td>\n",
       "      <td>2.106824</td>\n",
       "      <td>3.524250</td>\n",
       "      <td>2.770824</td>\n",
       "      <td>3.104320</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OutboundSampleRecording_0_1</td>\n",
       "      <td>12</td>\n",
       "      <td>I am going to t</td>\n",
       "      <td>-3.789234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.361769</td>\n",
       "      <td>2.156052</td>\n",
       "      <td>3.397645</td>\n",
       "      <td>3.008578</td>\n",
       "      <td>3.257230</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OutboundSampleRecording_0_2</td>\n",
       "      <td>12</td>\n",
       "      <td>he movies do yo</td>\n",
       "      <td>-3.789234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.016181</td>\n",
       "      <td>2.240076</td>\n",
       "      <td>4.008885</td>\n",
       "      <td>3.345069</td>\n",
       "      <td>3.415656</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OutboundSampleRecording_0_3</td>\n",
       "      <td>22</td>\n",
       "      <td>u my aquaintance and</td>\n",
       "      <td>-3.789234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.475892</td>\n",
       "      <td>2.258558</td>\n",
       "      <td>3.674884</td>\n",
       "      <td>3.071306</td>\n",
       "      <td>3.260052</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OutboundSampleRecording_0_3</td>\n",
       "      <td>12</td>\n",
       "      <td>u want to go</td>\n",
       "      <td>-3.789234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.172753</td>\n",
       "      <td>2.426229</td>\n",
       "      <td>3.590149</td>\n",
       "      <td>2.544041</td>\n",
       "      <td>2.835832</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OutboundSampleRecording_0_1</td>\n",
       "      <td>22</td>\n",
       "      <td>Hello there my griend</td>\n",
       "      <td>-3.789234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.107654</td>\n",
       "      <td>3.349199</td>\n",
       "      <td>3.581555</td>\n",
       "      <td>3.054449</td>\n",
       "      <td>2.949728</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename duration  \\\n",
       "0   OutboundSampleRecording_0_2       22   \n",
       "1   OutboundSampleRecording_0_1        6   \n",
       "2   OutboundSampleRecording_0_2        6   \n",
       "3   OutboundSampleRecording_0_4       22   \n",
       "4   OutboundSampleRecording_0_1        5   \n",
       "5   OutboundSampleRecording_0_5       22   \n",
       "6   OutboundSampleRecording_0_1        4   \n",
       "7   OutboundSampleRecording_0_1       12   \n",
       "8   OutboundSampleRecording_0_2       12   \n",
       "9   OutboundSampleRecording_0_3       22   \n",
       "10  OutboundSampleRecording_0_3       12   \n",
       "11  OutboundSampleRecording_0_1       22   \n",
       "\n",
       "                                     transcript  confidence age gender accent  \\\n",
       "0                          I am her  to make yo   -3.789234   0      0      0   \n",
       "1                                     Hello tre   -3.312910   0      0      0   \n",
       "2                                       my love   -3.312910   0      0      0   \n",
       "3                         then I qwill carry ea   -3.789234   0      0      0   \n",
       "4                     see the ocean ovwer there  -15.193325   0      0      0   \n",
       "5                         ch of you to the back   -3.789234   0      0      0   \n",
       "6   I am going to the movies do you want to go    -6.178956   0      0      0   \n",
       "7                               I am going to t   -3.789234   0      0      0   \n",
       "8                               he movies do yo   -3.789234   0      0      0   \n",
       "9                         u my aquaintance and    -3.789234   0      0      0   \n",
       "10                                u want to go    -3.789234   0      0      0   \n",
       "11                        Hello there my griend   -3.789234   0      0      0   \n",
       "\n",
       "    mos_pred  noi_pred  dis_pred  col_pred  loud_pred    model  \n",
       "0   2.581293  1.521738  4.343019  3.584870   3.764795  NISQAv2  \n",
       "1   1.809590  1.875911  3.833058  3.287724   2.815992  NISQAv2  \n",
       "2   1.742911  1.892213  3.259427  2.251022   2.962693  NISQAv2  \n",
       "3   2.635692  1.920747  3.986793  3.092535   3.441731  NISQAv2  \n",
       "4   2.008507  1.956141  3.775151  3.138167   2.895992  NISQAv2  \n",
       "5   2.189593  2.064310  3.807749  3.011560   3.009693  NISQAv2  \n",
       "6   2.058475  2.106824  3.524250  2.770824   3.104320  NISQAv2  \n",
       "7   2.361769  2.156052  3.397645  3.008578   3.257230  NISQAv2  \n",
       "8   2.016181  2.240076  4.008885  3.345069   3.415656  NISQAv2  \n",
       "9   2.475892  2.258558  3.674884  3.071306   3.260052  NISQAv2  \n",
       "10  2.172753  2.426229  3.590149  2.544041   2.835832  NISQAv2  \n",
       "11  2.107654  3.349199  3.581555  3.054449   2.949728  NISQAv2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <td>OutboundSampleRecording_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confidence</th>\n",
       "      <td>-3.789234</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accent</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mos_pred</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.172753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noi_pred</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.426229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis_pred</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.590149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_pred</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.544041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loud_pred</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.835832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NISQAv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transcript</th>\n",
       "      <td>NaN</td>\n",
       "      <td>u want to go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0              1\n",
       "filename    OutboundSampleRecording_4               \n",
       "duration                           12               \n",
       "confidence                  -3.789234               \n",
       "age                                 0               \n",
       "gender                              0               \n",
       "accent                              0               \n",
       "level_0                           NaN             11\n",
       "index                             NaN             11\n",
       "mos_pred                          NaN       2.172753\n",
       "noi_pred                          NaN       2.426229\n",
       "dis_pred                          NaN       3.590149\n",
       "col_pred                          NaN       2.544041\n",
       "loud_pred                         NaN       2.835832\n",
       "model                             NaN        NISQAv2\n",
       "transcript                        NaN  u want to go "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([concerned_params, chunks.loc[sub_chunks]], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename      OutboundSampleRecording_4\n",
       "duration                             12\n",
       "confidence                    -3.789234\n",
       "age                                   0\n",
       "gender                                0\n",
       "accent                                0\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(concerned_params, chunks[sub_chunks], how='left', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename      OutboundSampleRecording_4\n",
       "duration                             12\n",
       "confidence                    -3.789234\n",
       "age                                   0\n",
       "gender                                0\n",
       "accent                                0\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concerned_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('nisqa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42feb79fa54bc67696343d87c2233fc35a6874b7a7f7d28363247e7c5e2a5a81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
